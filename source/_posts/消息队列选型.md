---
layout: post
title: 消息队列选型
category: 消息队列
description: 消息队列选型
tags: 消息队列
date: 2024/09/19 23:11:10
---

转载自 作者：emoryliang

原文地址  
https://mp.weixin.qq.com/s/jWKHAic4Tt4Ohsj4pTmYFw
>
消息队列是重要的分布式系统组件，在高性能、高可用、低耦合等系统架构中扮演着重要作用。可用于异步通信、削峰填谷、解耦系统、数据缓存等多种业务场景。本文是关于消息队列（MQ）选型和常见问题的精心整理。在这篇文章中，我嗯将详细介绍消息队列的概念、作用以及如何选择适合自己需求的消息队列系统。

![](https://vqianxiao.github.io/blog/images/mq/mq1.png)

# 1 概诉

消息队列是分布式系统中重要的中间件，在高性能、高可用、低耦合等系统架构中扮演着重要作用。分布式系统可以借助消息队列的能力，轻松实现以下功能：

- 解耦：将一个流程的上下游拆解开，上游专注于生产消息，下游专注于处理消息；
- 广播：上游生产的消息可以轻松被多个下游服务处理；
- 缓冲：应对突发流量，消息队列扮演缓冲器的作用，保护下游服务，使其可以根据自身的实际消费能力处理消息；
- 异步：上游发送消息后可以马上返回，下游可以异步处理消息；
- 冗余：保留历史消息，处理失败或当出现异常时可以进行重试或者回溯，防止丢失；

# 2 架构简介

## 2.1 Kafka

### 2.1.1 系统架构

![](https://vqianxiao.github.io/blog/images/mq/mq2.png)
一个Kafka集群由多个Broker和一个ZooKeeper集群组成，Broker作为Kafka节点的服务器。同一个消息主题Topic可以由多个分区Partition组成，分区物理存储在Broker上。负载均衡考虑，同一个Topic的多个分区存储在多个不同的Broker上，为了提高可靠性，每个分区在不同的Broker都会存在副本。

ZooKeeper是一个分布式开源的应用程序协调服务，可以实现统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等工作。Kafka里的ZooKeeper主要有以下几个作用：

- Broker注册，当有Broker故障的时候能及时感知。
- Topic注册，维护Topic各分区的各副本所在的Broker节点，以及对应leader/follower的角色。
- Consumer注册，维护消费者组的offset以及消费者与分区的对应关系，实现负载均衡。

### 2.1.2 基本术语

**Producer:** 消息生产者。一般情况下，一条消息会被发送到特定的主题上。通常情况下，写入的消息会通过轮询将消息写入各分区。生产者也可以通过设定消息key值将消息写入指定分区。写入分区的数据越均匀Kafka的性能才能更好发挥。

**Topic:** Topic是一个抽象的虚拟概念，一个集群可以有多个Topic，作为一类消息的标识。一个生产者将消息发送到Topic，消费者通过订阅Topic获取分区消息。

**Partition:**
Partition是个物理概念，一个Topic对应一个或多个Partition。新消息会以追加的方式写入分区里，在同一个Partition里消息是有序的。Kafka通过分区，实现消息的冗余和伸缩性，以及支持物理上的并发读、写，大大提高了吞吐量。

**Replicas:**
一个Partition有多个Replicas副本。这些副本保存在Broker，每个broker存储着成百上千个不同主题和分区的副本，存储的内容分为两种：master副本，每个Partition都有一个Master副本，所有内容的写入和消费都会经过Master副本；follower副本不处理任何客户端的请求，只同步master的内容进行复制。如果master发生了异常，很快会有一个follower成为新的master。

**Consumer:** 消息读取者。消费者订阅主题，并按照一定顺序读取消息。Kafka保证每个分区只能被一个消费者使用。

**Offset:** 偏移量是一种元数据，是不断递增的整数。在消息写入时Kafka会把它添加到消息里。在分区内偏移量是唯一的。消费过程中，会将最后读取的偏移量存储在Kafka中，消费者关闭偏移量不会丢失，重启会继续从上次位置开始消费。

**Broker:**
独立的Kafka服务器。一个Topic有N个Partition，一个集群有N个Broker，那么每个Broker都会存储一个这个Topic的Partition。如果某个Topic有N个partition，集群有（N+M）个Broker，那么其中有N个Broker存储该Topic的一个Partition，剩下的M个Broker不存储该Topic的Partition数据。如果某个Topic有N个Partition，集群中broker数目少于N个，那么一个Broker存储该Topic的一个或多个Partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。

## 2.2 Pulsar

### 2.2.1 系统架构

![](https://vqianxiao.github.io/blog/images/mq/mq3.png)
Pulsar有三个重要的组件，Broker、BookKeeper和ZooKeeper，Broker是无状态服务，客户端需要连接到Broker上进行消息的传递。BookKeeper与ZoKeeper是有状态服务。
BookKeeper的节点叫Bookie，负责存储消息和游标，ZooKeeper存储Broker和Bookie的元数据。Pulsar以这种架构，实现存储和计算分离，Broker负责计算，Bookie负责有状态存储。
![](https://vqianxiao.github.io/blog/images/mq/mq4.png)
Pulsar的多层架构影响了存储数据的方式。Pulsar将Topic分区划分为分片（Segment）,然后将这些分片存储在Apache
BookKeeper的存储节点上，以提高性能、可伸缩性和可用性。
Pulsar的分布式日志以分片为中心，借助扩展日志存储（通过Apache
bookKeeper）实现，内置分层存储支持，因此分片可以均匀地分布在存储节点上。由于与任一给定Topic相关的数据都不会与特定存储节点进行捆绑，因此很容易替换存储节点或扩缩容。另外，集群中最小或最慢的节点也不会成为存储或带宽的短板。

### 2.2.2 基本术语

**Property:** 代表租户，每个property都可以代表一个团队、一个功能、一个产品线。一个property可包含多个namespace，多租户是一种资源隔离手段，可以提高资源利用率。

**Namespace:**
Pulsar的基本管理单元，在namespace级别可设置权限、消息TTL、Retention策略等。一个namespace里的所有topic都继承相同的设置。命名空间分为两种：本地命名空间，只在集群内可见；全局命名空间对多个集群可见。
![](https://vqianxiao.github.io/blog/images/mq/mq5.png)

**Producer:** 数据生产方，负责创建消息并将消息投递到Pulsar中。

**Consumer:** 数据消费方，连接到Pulsar接收消息并进行相应的处理。

**Broker:** 无状态Proxy服务，负责接收消息、传递消息、集群负载均衡等操作，它对client屏蔽了服务端读写流程的复杂性，是保证数据一致性与数据负载均衡的重要角色。Broker不会持久化保存元数据。可以扩容但不能缩容。

**BookKeeper:**
有状态，负责持久化存储消息。当集群扩容时，Pulsar会在新增BookKeeper和Segment（即BookKeeper的Ledger），不需要想kafka一样扩容时进行ReBalance。扩容结果时Fragments跨多个Bookies以带状分布，同一个Ledger的Fragments分布在多个Bookie上，导致读取和写入会在多个Bookies之间跳跃。

**ZooKeeper:** 存储Pulsar、BookKeeper的元数据，集群配置等信息，负责集群间的协调、服务发现等。

**Topic:** 用作从producer到consumer传输消息。Pulsar在Topic级别拥有一个leader
Broker，称之为拥有Topic的所有权，针对该Topic所有的R/W都经过该Broker完成。Topic的Ledger和Fragment之间映射关系等元数据存储在Zookeeper中，Pulsar Broker需要事实跟踪这些关系进行读写流程。

**Ledger:** 即Segment，Pulsar底层数据以Ledger的形式存储在BookKeeper上。是Pulsar删除的最小单位。

**Fragment:** 每个Ledger由若干个Fragment组成。

## 2.3 RocketMQ
### 2.3.1 系统框架
![](https://vqianxiao.github.io/blog/images/mq/mq6.png)
RocketMQ是阿里开源的消息中间件，它是一个开源的分布式消息传递和流式数据平台。总共有四大部分：NameServer，Broker，Producer，Consumer。

NameServer主要用来管理brokers以及路由信息。broker服务器启动时会注册到NameServer上，并且两者之间保持心跳监测机制，以此来保证NameServer知道broker的存活状态。而且，每一台NameServer都存有全部的broker集群信息和生产者/消费者客户端的请求信息。

Broker负载管理消息存储分发，主从数据同步，为消息建立索引，提供消息查询等能力。

### 2.3.2 基本术语
**Topic:** 一个Topic可以有0个、1个多个生产者向其发送消息，一个生产者也可以同时向不同的Topic发送消息。一个Topic也可以被0个、1个、多个消费者订阅。

**Tag:** 消息二级类型，可以为用户提供额外的灵活度，一条消息可以没有Tag。

**Producer:** 消息生产者。

**Broker:** 存储消息，以Topic为纬度轻量级的队列；转发消息，单个Broker节点与所有的NameServer节点保持长连接及心跳，会定时将Topic信息注册到NameServer。

**Consumer:** 消息消费者，负责接收并消费消息。

**MessageQueue:** 消息的物理管理单位，一个Topic可以有多个Queue，Queue的的引入是西安了水平扩展的能力。

**NameServer:** 负责对元数据的管理，包括Topic和路由信息，每个NameServer之间是没有通信的。

**Group:** 一个组可以订阅多个Topic，ProducerGroup、ConsumerGroup分别是一类生产者和一类消费者。

**Offset:** 通过Offset访问存储单元，RocketMQ中所有消息都是持久化的，且存储单元定长。Offset为Java Long类型，理论上100年内不会溢出，所以认为Message Queue是无限长的数据，Offset是下标。

**Consumer:** 支持PUSH和PULL两种消费模式，支持集群消费和广播消费。

## 2.4 RabbitMQ
### 2.4.1 系统框架
![](https://vqianxiao.github.io/blog/images/mq/mq7.png)
RabbitMQ基于AMQP协议来实现，主要由Exchange和Queue两部分组成，然后通过RoutingKey关联起来，消息投递到Exchange然后通过Queue接收。

### 2.4.2 基本术语
**Broker:** 接收客户端连接实体，实现AMQP消息队列和路由功能。

**Virtual Host:** 是一个虚拟概念，权限控制的最小单位。一个Virtual Host里包含多个Exchange和Queue。

**Exchange:** 接收消息生产者的消息并将消息转发到队列。发送消息时根据不同ExchangeType决定路由规则，ExchangeType常用的有：direct、fanout和topic三种。

**Message Queue:** 消息队列，存储被消费的消息。

**Message:** 由Header和Body组成，Header是生产者添加的各种属性，包含Message是否持久化、哪个MessageQueue接收、优先级。Body是具体的消息内容。

**Binding:** Binding连接起了Exchange和Message Queue。在服务器运行时，会生成一张路由表，这张路由表上记录者MessageQueue的条件和BindingKey值。当Exchange收到消息后，会解析消息中的Header得到BindingKey，并根据路由表和ExchangeType将消息发送到对应的MessageQueue。最终的匹配模式是由ExchangeType决定。

**Connection:** 在Broker和客户端之间的TCP连接。

**Channel:** 信道。Broker和客户端只有tcp连接是不能发送消息的，必须创建信道。AMQP协议规定只有通过Channel才能执行AMQP命令。一个Connection可以包含多个Channel。之所以需要建立Channel，是因为每个TCP连接都是很宝贵的。如果每个客户端、每个线程都需要和Broker交互，都需要维护一个TCP连接的话是很耗费机器资源的，一般建议共享Connection。RabbitMQ不建议客户端线程之间共享Channel，至少保证同一Channel发消息是串行的。

**Command:** AMQP命令，客户端通过Command来完成和AMQP服务器的交互。

## 2.5 NSQ
### 2.5.1 系统框架
![](https://vqianxiao.github.io/blog/images/mq/mq8.png)
NSQ主要有nsqlookup、nsqd两部分组成:
- Nsqlookup为守护进程，负责管理拓扑信息并提供发现服务。客户端通过查询nsqlookupd获取指定Topic所在的nsqd节点。nsqd往nsqlookup上注册和广播自身topic和channel的信息。
- nsqd在服务端运行的守护进程，负责接收，排队，投递消息给客户端。

NSQ由3个守护进程组成：
- nsqd是接收、队列和传送消息到客户端的守护进程。
- nsqlookupd是管理的拓扑信息，并提供了最终一致发现服务的守护进程。客户端通过查询nsqlookupd获取指定Topic所在的nsqd节点。nsqd往nsqlookup上注册和广播自身topic和channel的信息。
- nsqadmin是一个WebUI来实时监控集群（和执行各种管理任务）。

# 3选型要点
## 3.1选型参考
- 消息顺序：发送到队列的消息，消费时是否可以保证消费的顺序。
- 伸缩：当消息队列性能有问题，比如消费太慢，是否可以快速支持扩容；当消费队列过多，浪费系统资源，是否可以支持缩容。
- 消息留存：消息消费成功后，是否还会继续保留在消息队列。
- 容错性：当一条消息消费失败后，是否有一些机制，保证这条消息一定能成功，比如异步第三方退款消息，需要保证这条消息消费掉，才能确定给用户退款成功，所以必须保证这条消息消费的准确性。
- 消息可靠性：是否会存在丢消息的情况，比如有A/B两个消息，最后只有B消息能消费，A消息丢失
- 消息时序：主要包括“消息存活时间”和“延迟消息”
- 吞吐量：支持的最高并发数
- 消息路由：根据路由规则，只订阅匹配路由规则的消息，比如有A/B两者规则的消息，消费者可以只订阅A消息，B消息不会消费。

## 3.2消息队列对比
![](https://vqianxiao.github.io/blog/images/mq/mq9.png)
![](https://vqianxiao.github.io/blog/images/mq/mq10.png)

# 4功能剖析
## 4.1消费推拉模式
客户端消费者获取消息的方式，Kafka和RocketMQ是通过长轮训Pull的方式拉取消息，RabbitMQ、Pulsar、NSQ都是通过Push的方式。
pull类型的消息队列更适合高吞吐量的场景，允许消费者自己进行流量控制，根据消费者实际的消费能力去获取消息。而push类型的消息队列，实时性更好，但需要有一套良好的流控策略(backpressure)当消费者消费能力不足时，减少push的消费数量，避免压垮消费端。

## 4.2延迟队列
消息延迟投递，当消息产生送达消息队列时，有些业务场景并不希望消费者立刻收到消息， 而是等待特定时间后，消费者才能拿大这个消息进行消费。延迟队列一般分为两种，基于消息的延迟和基于队列的延迟。
基于消息的延迟指为每条消息设置不同的延迟时间，当队列有新消息进入的时候根据延迟时间排序，当然这样会对性能造成较大影响。
另一种基于队列的延迟指的是设置不同延迟级别的队列，队列中每个消息的延迟时间都是相同的，这样免去了基于延迟时间排序对性能带来的损耗，通过一定的扫描策略即可投递超时的消息。
延迟消息的使用场景比如异常检测重试，订单超时取消等，例如：
- 服务请求异常，需要将异常请求放到单独的队列，隔5分钟后进行重试。
- 用户购买商品，但一直处于未支付状态，需要定期提醒用户支付，超时则关闭订单。
- 面试或者会议预约，在面试或者会议开始前半小时，发送通知再次提醒。
Kafka不支持延迟消息。Pulsar支持秒级的延迟消息，所有延迟投递的消息会被Delayed Message Tracker记录对应的index，consumer在消费时，会先去Delayed Message Tracker检查，是否有到期需要投递的消息，
如果有到期的的消息，则从Tracker中拿出对应的index，找到对应的消息进行消费，如果没有到期的消息，则直接消费正常的消息。对于长时间的延迟消息，会被存储在磁盘中，当快到延迟间隔时才被加载到内存里。
![](https://vqianxiao.github.io/blog/images/mq/mq11.png)
RocketMQ开源版本延迟消息临时存储在一个内部主题中，不支持任意时间精度，支持特定的level，例如定时5s，10s，1m等。
RabbitMQ需要安装一个rabbitmq_delayed_message_exchange插件, 支持任意时间精度。
NSQ通过内存中的优先级队列来保存延迟消息，支持秒级精度，最多2个小时延迟。

## 4.3死信队列
![](https://vqianxiao.github.io/blog/images/mq/mq12.png)
由于某些原因消息无法被正确的投递，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般被称为死信队列。与此对应的还有一个“回退队列”的概念，试想如果消费者在消费时发生了异常，那么就不会对这一次消费进行确认（Ack），进而发生回滚消息的操作之后消息始终会被放在队列的顶部，
然后不断被处理和回滚，导致队列陷入死循环。为了解决这个问题，可以为每个队列设置一个回退队列，它和死信队列都是为异常的处理提供的一种机制保障。实际情况下，回退队列的角色可以由死信队列和重试队列来扮演。
Kafka没有死信队列，通过Offset的方式记录当前消费的偏移量。

Pulsar有重试机制，当某些消息第一次被消费者消费后，没有得到正常的回应，则会进入重试Topic中，当重试达到一定次数后，停止重试，投递到死信Topic中。

RocketMQ通过DLQ来记录所有消费失败的消息。

RabbitMQ是利用类似于延迟队列的形式实现死信队列。

NSQ没有死信队列。

## 4.4优先级队列
在一些业务场景下，我们需要优先处理一些消息，比如银行里面的金卡用户、银卡客户优先级高于普通客户，他们的业务需要优先处理。如下图
![](https://vqianxiao.github.io/blog/images/mq/mq13.png)
优先级队列不同于先进先出队列，优先级高的消息具备优先被消费的特权，这样可以为下游提供不同消息级别的保证。不过优先级队列需要一个前提：如果消费者的消费速度大于消息的生产速度，并且消息中间件服务器没有消息堆积，那么优先级队列就没有意义了，
因为生产者刚发送完一条消息就被消费者消费了，那么就相当于 Broker 中至多只有一条消息，对于单条消息来说优先级是没有什么意义的。
Kafka、RocketMQ、Pulsar、NSQ 不支持优先级队列，可以通过不同的队列来实现消息优先级。
RabbitMQ 支持优先级消息。

## 4.5消息回溯
一般消息在消费完成之后就被处理了，之后再也不能消费到该条消息。消息回溯正好相反，是指消息在消费完成之后，还能消费到之前被消费掉的消息。对于消息而言，经常面临的问题是“消息丢失”，至于是真正由于消息中间件的缺陷丢失还是由于使用方的误用而丢失一般很难追查，如果消息中间件本身具备消息回溯功能的话，可以通过回溯消费复现“丢失的”消息进而查出问题的源头之所在。消息回溯的作用远不止与此，比如还有索引恢复、本地缓存重建，有些业务补偿方案也可以采用回溯的方式来实现。
Kafka 支持消息回溯，可以根据时间戳或指定 Offset，重置 Consumer 的 Offset 使其可以重复消费。

Pulsar 支持按时间对消息进行回溯。

RocketMQ 支持按时间回溯，实现的原理跟 Kafka 一致。

RabbitMQ 不支持回溯，消息一旦标记确认就会被标记删除。

NSQ 一般消息是不可回溯的，但可以通过 nsq_to_file 工具，将消息写入到文件，然后从文件里重放消息。

## 4.6消息持久化
流量削峰是消息中间件的一个非常重要的功能，而这个功能其实得益于其消息堆积能力。从某种意义上来讲，如果一个消息中间件不具备消息堆积的能力，那么就不能把它看做是一个合格的消息中间件。消息堆积分内存式堆积和磁盘式堆积。一般来说，磁盘的容量会比内存的容量要大得多，对于磁盘式的堆积其堆积能力就是整个磁盘的大小。从另外一个角度讲，消息堆积也为消息中间件提供了冗余存储的功能。

Kafka 和 RocketMQ 直接将消息刷入磁盘文件中进行持久化，所有的消息都存储在磁盘中。只要磁盘容量够，可以做到无限消息堆积。

RabbitMQ 是典型的内存式堆积，但这并非绝对，在某些条件触发后会有换页动作来将内存中的消息换页到磁盘（换页动作会影响吞吐），或者直接使用惰性队列来将消息直接持久化至磁盘中。

Pulsar 消息是存储在 BookKeeper 存储集群上，也是磁盘文件。

NSQ 通过 nsq_to_file 工具，将消息写入到文件。

## 4.7消息确认机制
消息队列需要管理消费进度，确认消费者是否成功处理消息，使用 push 的方式的消息队列组件往往是对单条消息进行确认，对于未确认的消息，进行延迟重新投递或者进入死信队列。

Kafka通过 Offset 的方式确认消息。
1）发送方确认机制 ack=0，不管消息是否成功写入分区 ack=1，消息成功写入首领分区后，返回成功 ack=all，消息成功写入所有分区后，返回成功。

2）接收方确认机制 自动或者手动提交分区偏移量，早期版本的 kafka 偏移量是提交给 Zookeeper 的，这样使得 zookeeper 的压力比较大，更新版本的 kafka 的偏移量是提交给 kafka 服务器的，不再依赖于 zookeeper 群组，集群的性能更加稳定。

RocketMQ与 Kafka 类似也会提交 Offset，区别在于消费者对于消费失败的消息，可以标记为消息消费失败，Broker 会重试投递，如果累计多次消费失败，会投递到死信队列。

RabbitMQ和 NSQ 类似，消费者确认单条消息，否则会重新放回队列中等待下次投递。
1）发送方确认机制，消息被投递到所有匹配的队列后，返回成功。如果消息和队列是可持久化的，那么在写入磁盘后，返回成功。支持批量确认和异步确认。

2）接收方确认机制，设置 autoAck 为 false，需要显式确认，设置 autoAck 为 true，自动确认。当 autoAck 为 false 的时候，rabbitmq 队列会分成两部分，一部分是等待投递给 consumer 的消息，一部分是已经投递但是没收到确认的消息。如果一直没有收到确认信号，并且 consumer 已经断开连接，rabbitmq 会安排这个消息重新进入队列，投递给原来的消费者或者下一个消费者。未确认的消息不会有过期时间，如果一直没有确认，并且没有断开连接，rabbitmq 会一直等待，rabbitmq 允许一条消息处理的时间可以很久很久。

Pulsar使用专门的 Cursor 管理。累积确认和 Kafka 效果一样；提供单条或选择性确认。

## 4.8消息TTL
消息 TTL 表示一条消息的生存时间，如果消息发出来后，在 TTL 的时间内没有消费者进行消费，消息队列会将消息删除或者放入死信队列中。

Kafka 根据设置的保留期来删除消息。有可能消息没被消费，过期后被删除。不支持 TTL。

Pulsar 支持 TTL，如果消息未在配置的 TTL 时间段内被任何消费者使用，则消息将自动标记为已确认。消息保留期与消息 TTL 之间的区别在于：消息保留期作用于标记为已确认并设置为已删除的消息，而 TTL 作用于未 ack 的消息。上面的图例中说明了 Pulsar 中的 TTL。例如，如果订阅 B 没有活动消费者，则在配置的 TTL 时间段过后，消息 M10 将自动标记为已确认，即使没有消费者实际读取该消息。

RocketMQ 提及到消息 TTL 的资料比较少，不过看接口似乎是支持的。

RabbitMQ 有两种方式，一个是声明队列的时候在队列属性中设置，整个队列中的消息都有相同的有效期。还可以发送消息的时候给消息设置属性，可以位每条消息都设置不同的 TTL。

NSQ 似乎还没支持，有一个 Feature Request 的 Issue 处于 Open 状态。

## 4.9多租户隔离
多租户是指通过一个软件实例为多个租户提供服务的能力。租户是指对系统有着相同“视图”的一组用户。不支持多租户的系统里边，往往要为不同用户或者不同集群创建多个消息队列实例实现物理隔离，这样会带来较高的运维成本。作为一种企业级的消息系统，Pulsar 的多租户能力按照设计可满足下列需求：

- 确保严苛的 SLA 可顺利满足。
- 保证不同租户之间的隔离。
- 针对资源利用率强制实施配额。
- 提供每租户和系统级的安全性。
- 确保低成本运维以及尽可能简单的管理。

Pulsar 通过下列方式满足了上述需求：
- 通过为每个租户进行身份验证、授权和 ACL（访问控制列表）获得所需安全性。
- 为每个租户强制实施存储配额。
  
以策略的方式定义所有隔离机制，策略可在运行过程中更改，借此降低运维成本并简化管理工作。

## 4.10消息顺序性
消息顺序性是指保证消息有序。消息消费顺序跟生产的顺序保持一致。

Kafka 保证了分区内的消息有序。

Pulsar 支持两种消费模式，独占订阅的流模式只保证了消息的顺序性，共享订阅队列模型不保证有序性。

RocketMQ 需要用到锁来保证一个队列同时只有一个消费者线程进行消费，保证消息的有序性。

RabbitMQ 顺序性的条件比较苛刻，需要单线程发送、单线程消费，并且不采用延迟队列、优先级队列等高级功能。

NSQ 是利用了 golang 自身的 case/select 实现的消息分发，本身不提供有序性保障，不能够把特性消息和消费者对应起来，无法实现消息的有序性。

## 4.11消息查询
在实际开发中，经常要查看 MQ 中消息的内容，比如通过某个 MessageKey/ID，查询到 MQ 的具体消息。或者是对消息进行链路追踪，知道消息从哪里来，发送到哪里去，进而快速对问题进行排查定位。

Kafka 存储层是以分布式提交日志的形式实现，每次写操作都顺序追加到日志的末尾。读也是顺序读。不支持检索功能。





